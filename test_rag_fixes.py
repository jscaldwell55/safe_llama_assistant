#!/usr/bin/env python3
"""
Test the RAG fixes without requiring HF API calls
"""

import os
import sys
import pickle
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from context_formatter import ContextFormatter
from prompt import format_conversational_prompt

def test_with_real_data():
    """Test improvements with real data from the index"""
    print("ğŸ” Testing with real data from the RAG index...")
    
    try:
        # Load real data from the index
        with open('faiss_index/metadata.pkl', 'rb') as f:
            texts, metadata = pickle.load(f)
        
        print(f"Loaded {len(texts)} real chunks from index")
        
        # Take a sample of real chunks
        sample_chunks = texts[:5] if len(texts) >= 5 else texts
        
        formatter = ContextFormatter()
        test_query = "What are the side effects of Lexapro?"
        
        print("\nOriginal chunks (first 100 chars):")
        for i, chunk in enumerate(sample_chunks):
            print(f"  {i+1}: {chunk[:100]}...")
        
        # Test the complete formatting pipeline
        formatted_context = formatter.format_enhanced_context(
            chunks=sample_chunks,
            query=test_query,
            conversation_context="",
            conversation_entities=[]
        )
        
        print(f"\nFormatted context length: {len(formatted_context)} characters")
        print("Formatted context preview:")
        print("-" * 50)
        print(formatted_context[:400] + "..." if len(formatted_context) > 400 else formatted_context)
        print("-" * 50)
        
        # Generate the final prompt
        final_prompt = format_conversational_prompt(
            query=test_query,
            formatted_context=formatted_context,
            conversation_context="",
            intent="question"
        )
        
        print(f"\nFinal prompt length: {len(final_prompt)} characters")
        print("Final prompt structure check:")
        
        # Verify the improvements are in place
        checks = [
            ("Context boundaries present", "---CONTEXT---" in final_prompt and "---END CONTEXT---" in final_prompt),
            ("Anti-verbatim instruction", "Do NOT copy the context verbatim" in final_prompt),
            ("Synthesis instruction", "synthesize the information" in final_prompt),
            ("Context-only instruction", "based *only* on the context" in final_prompt),
            ("Clear role definition", "Assistant's Answer:" in final_prompt)
        ]
        
        for check_name, passed in checks:
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {check_name}")
        
        all_passed = all(passed for _, passed in checks)
        
        if all_passed:
            print("âœ… All prompt improvements successfully applied to real data")
        else:
            print("âŒ Some prompt improvements missing")
        
        return all_passed
        
    except FileNotFoundError:
        print("âŒ No RAG index found. Please build the index first.")
        return False
    except Exception as e:
        print(f"âŒ Error testing with real data: {e}")
        return False

def show_before_after_comparison():
    """Show a comparison of before/after prompt structure"""
    print("\nğŸ“Š Before/After Comparison:")
    print("="*60)
    
    test_query = "What are the side effects?"
    test_context = "Side effects may include nausea and headache."
    
    # Old style prompt (what it might have looked like before)
    old_prompt = f"""Context: {test_context}

User Question: {test_query}

Answer:"""
    
    # New improved prompt
    new_prompt = format_conversational_prompt(
        query=test_query,
        formatted_context=test_context,
        conversation_context="",
        intent="question"
    )
    
    print("BEFORE (weak prompt):")
    print("-" * 30)
    print(old_prompt)
    print("-" * 30)
    
    print("\nAFTER (improved prompt):")
    print("-" * 30)
    print(new_prompt[:500] + "..." if len(new_prompt) > 500 else new_prompt)
    print("-" * 30)
    
    print("\nKey improvements added:")
    print("  ğŸ“ Explicit instructions to synthesize, not copy")
    print("  ğŸš« Anti-verbatim copying instructions")
    print("  ğŸ“‹ Clear context boundaries with ---CONTEXT--- markers")
    print("  ğŸ¯ Role clarity: 'Assistant's Answer:' vs generic 'Answer:'")
    print("  ğŸ”’ Strict context-only constraint")

def main():
    """Run the comprehensive RAG fixes test"""
    print("ğŸ› ï¸  Testing RAG System Fixes")
    print("="*50)
    
    # Test with real data if available
    real_data_test = test_with_real_data()
    
    # Show comparison
    show_before_after_comparison()
    
    print("\n" + "="*50)
    print("ğŸ¯ RAG FIXES SUMMARY")
    print("="*50)
    
    print("âœ… PROBLEM 1 SOLVED: Poorly Formatted Source Data")
    print("   â†’ Added clean_chunk_text() method to remove FAQ formatting")
    print("   â†’ Integrated cleaning into context formatting pipeline")
    print("   â†’ Handles patterns like 'User Question:', 'Answer:', etc.")
    
    print("\nâœ… PROBLEM 2 SOLVED: Weak Prompt Template")
    print("   â†’ Added explicit 'based *only* on the context' instruction")
    print("   â†’ Added 'Do NOT copy the context verbatim' instruction")
    print("   â†’ Added clear context boundaries with ---CONTEXT--- markers")
    print("   â†’ Added synthesis instruction: 'synthesize the information into a natural response'")
    print("   â†’ Changed from generic 'Answer:' to specific 'Assistant's Answer:'")
    
    if real_data_test:
        print("\nğŸ‰ All fixes successfully applied and tested with real data!")
    else:
        print("\nâš ï¸  Fixes applied but could not test with real index data")
    
    print("\nğŸ“‹ NEXT STEPS:")
    print("   1. The RAG system will now provide cleaner, more conversational responses")
    print("   2. The model should synthesize information instead of copying chunks")
    print("   3. Test with actual queries through the Streamlit app to verify behavior")

if __name__ == "__main__":
    main()